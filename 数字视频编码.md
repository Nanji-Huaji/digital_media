## 数字化
数字电视广播系统组成：信号源端、压缩编码、系统复用、传输系统
模拟信号数字化：采样、量化、编码
RGB->编码矩阵->采样、量化、编码->$YC_RC_B$
（这里好像不重要）
$$
\begin{align}
Y=0.299R+0.587G+0.114B & \\
C_R=0.713(R-Y)+350 & \\
C_B=0.564(B_Y)+350
\end{align}
$$
350mV是为了使得色差信号的数值动态范围在0~700mV

### 取样方式
- 4<=>100% 未抽样
- 每100%量化为若干bit
- `J:a:b`是一个标准，用来描述色度相对于亮度的抽样率。**第一个 ‘4’**: 代表**亮度 (Y') 的抽样率**，a 描述第一行的 `J` 个亮度样本中，对应了多少个色度样本（Cb 和 Cr），`b` 描述的是在第二行像素中，相对于第一行，有多少**新**的、**不同**的色度样本。
#### 4:4:4取样
- 每个分量的每个样本：8（消费，计算机）～10（演播室编辑）bit
- 每个像素的样本：24～30bit
- 四个像素有4个RGB或4个YCrYb样本
![[Pasted image 20251126211809.png]]
#### 4:2:2取样
在**水平扫描方向**上，每 2 个 Y 样本有 1 个 Cb 样本和一个 Cr 样本
**4:2:2 保留了全部的垂直色彩信息，但只保留了一半的水平色彩信息。**
- 每2个Y <-> 1个Cr，1个Cb
- 每个像素：2个样本
![[Pasted image 20251126214605.png]]
#### 4:1:1取样
![[Pasted image 20251127141912.png]]
#### 4:2:0 MPEG-1取样
它将颜色信息的垂直和水平分辨率都降低为亮度信息的一半。
MPEG-1 的 4:2:0 抽样规则是“与左上角重合”
```plaintext
   (Cr, Cb,Y) --- (Y)      <-- 色度样本与左上角的亮度样本在同一位置
     |         |
     |         |
    (Y) ----- (Y)

```
#### 4:2:0 MPEG-2取样
与 MPEG-1 的 4:2:0 相比，MPEG-2 的子采样在水平方向上没有半个象素的偏移。


>例： 视频某帧的 8×8 块的 Cr 信号值分别如下图 1 所示：:
> (1)画出 Cr 信号经过 4：2：0 MPEG-1 取样后的信号值。
> ![[Pasted image 20251126211614.png]]

解：
$$
Cr_{original} =
\left(
\begin{matrix}
1 & 1 & 0 & 10 & 10 & 1 & 0 & 1 \\
1 & 1 & 0 & 10 & 0 & 0 & 0 & 0 \\
1 & 5 & 0 & 10 & 0 & 0 & 3 & 2 \\
1 & 5 & 0 & 18 & 10 & 1 & 0 & 2 \\
1 & 5 & 0 & 18 & 10 & 1 & 3 & 2 \\
1 & 5 & 0 & 18 & 10 & 1 & 3 & 2 \\
3 & 0 & 0 & 18 & 10 & 1 & 3 & 2 \\
3 & 0 & 0 & 18 & 10 & 1 & 2 & 2 \\
\end{matrix}
\right)
$$
保留2\*2方格中左上角的元素，即：
$$
Cr_{original} =
\left(
\begin{matrix}
1 & 0 & 0 & 0 & 10 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
1 & 0 & 0 & 0 & 0 & 0 & 3 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
1 & 0 & 0 & 0 & 10 & 0 & 3 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
3 & 0 & 0 & 0 & 10 & 0 & 3 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
\end{matrix}
\right)
$$
去掉0，变为
$$

Cr_{sampled} =

\left(

\begin{matrix}

1 & 0 & 10 & 0 \\

1 & 0 & 0 & 3 \\

1 & 0 & 10 & 3 \\

3 & 0 & 10 & 3 \\

\end{matrix}

\right)

$$
### 熵编码
#### 无失真编码
- 游程数据编码
- 变字长编码
	- 哈夫曼编码
	- 算数编码
#### 有失真编码
- 量化
- KLT编码
- 离散余弦变换
- 小波变换
- DPCM编码
- 运动估计与补偿

**冗余度：** 定义信息量为$I(x)=-logP(x)$，信息熵是所有可能事件的信息量的平均，即$H(X) = \mathbf{E}\{I(x_j)\} = \sum_{i=1}^n P(x_i)I(x_i) = -\sum_{i=1}^n P(x_i) \log P(x_i)$
当且仅当$X_i$非等概时有冗余。

| 编码   | 冗余            |
| ---- | ------------- |
| 变换编码 | 图像的空间冗余       |
| 预测编码 | 图像或视频的空间或时间冗余 |
| 熵编码  | 信息熵冗余         |
#### 变字长编码定理
对于一个信息源，我们可以找到一种编码方式，使其平均码长无限接近于该信息源的熵，但不可能小于它。
最佳平均码字长度：$\bar{I_{av}}=\sum_{k=1}^{K-1}I_kP(a_k)$。
且$H(X) < I_{av} < H(X) + 1$。
### Huffman 编码
#### 步骤一：构建霍夫曼树 (The Huffman Tree)
1. **统计频率**：扫描整个数据，统计每个字符（或符号）出现的频率（次数）。
2. **创建节点**：为每个字符创建一个“叶子节点”，每个节点包含字符本身和它的频率。
3. **迭代构建**： 
	1. a. 将所有节点放入一个列表或优先队列中，按频率从小到大排序。 
	2. b. 从列表中取出**频率最低的两个节点**。 
	3. c. 创建一个新的“内部节点”（非叶子节点），其频率是这两个子节点频率之和。
	4. d. 将这两个取出的节点作为新节点的左右子节点。**（哪边是左、哪边是右不影响最终的码长，但会影响具体的编码结果）
	5. e. 将新创建的内部节点放回列表中。 
	6. f. **重复步骤 a-e**，直到列表中只剩下一个节点。这个最后的节点就是霍夫t曼树的**根节点**。
#### 步骤二：生成编码表 (The Codebook)

1. **分配二进制码**：从根节点开始遍历整个霍夫曼树。
2. 约定一个规则，例如：**向左走记为 `0`，向右走记为 `1`**。
3. 从根节点到每个叶子节点的路径，就构成了该叶子节点对应字符的霍夫曼编码。
#### 算术编码
算术编码将**整个消息**映射到 `[0, 1)` 区间内的一个**小数**。消息越长，这个小数所需的精度就越高。
算术编码**不**需要码表。
#### 1. 初始设置

- **符号和概率**: 首先，需要知道数据源中每个符号的出现概率。
    - A: 0.5 (50%)
    - B: 0.3 (30%)
    - C: 0.2 (20%)
- **初始区间**: 我们从代表所有可能性的区间 `[0.0, 1.0)` 开始。
#### 2. 划分初始区间

根据符号的概率，我们将 `[0, 1)` 区间划分为几个子区间：

- **A**: `[0.0, 0.5)` (占据前 50% 的空间)
- **B**: `[0.5, 0.8)` (占据接下来的 30% 空间, )
- **C**: `[0.8, 1.0)` (占据最后的 20% 空间, )

[0.0] --------- A (50%) --------- [0.5] ---- B (30%) ---- [0.8] -- C (20%) -- [1.0]
#### 3. 编码第一个字符："C"

我们要编码的第一个字符是 'C'。

- 我们选择 'C' 对应的子区间 `[0.8, 1.0)` 作为我们新的“当前区间”。
- 现在，整个消息的编码结果一定是一个以 `0.8...` 开头的小数。
#### 4. 编码第二个字符："A"

接下来编码 'A'。我们**在新的当前区间 `[0.8, 1.0)` 内，再次按照原始概率进行划分**。

- 当前区间的范围长度 (range) 是 。
- 将这个 `0.2` 的范围进行划分：
    - **A's new sub-interval**: `[0.8, 0.8 + 0.2 * 0.5)` = `[0.8, 0.9)`
    - **B's new sub-interval**: `[0.9, 0.9 + 0.2 * 0.3)` = `[0.9, 0.96)`
    - **C's new sub-interval**: `[0.96, 0.96 + 0.2 * 0.2)` = `[0.96, 1.0)`

我们要编码的是 'A'，所以我们选择 'A' 的新子区间 `[0.8, 0.9)` 作为下一个“当前区间”。
#### 5. 编码第三个字符："B"

最后编码 'B'。我们在当前区间 `[0.8, 0.9)` 内重复这个过程。

- 当前区间的范围长度 (range) 是 。
- 将这个 `0.1` 的范围进行划分：
    - **A's final sub-interval**: `[0.8, 0.8 + 0.1 * 0.5)` = `[0.8, 0.85)`
    - **B's final sub-interval**: `[0.85, 0.85 + 0.1 * 0.3)` = `[0.85, 0.88)`
    - **C's final sub-interval**: `[0.88, 0.88 + 0.1 * 0.1)` = `[0.88, 0.9)`

我们要编码的是 'B'，所以最终的区间是 `[0.85, 0.88)`。

对其的编码原则是，**找到一个最短的二进制小数，使其唯一地落在这个区间**。
取最短的`0.111`作为编码结果。

下面演示解码，
解码器接收到二进制码 `111`，并使用完全相同的概率模型来还原消息。
**初始准备:**

1. **二进制码**: `111`
2. **转换为十进制值**: `value` = 0.875
3. **初始区间**: `[0.0, 1.0)`
4. **终止条件**: 假设我们知道消息长度为3。
#### 步骤 1: 解码第一个字符

1. **定位**: `value` (0.875) 落在初始区间 `[0.0, 1.0)` 的哪个子区间？
    - A: `[0.0, 0.5)`
    - B: `[0.5, 0.8)`
    - **C: `[0.8, 1.0)`** <-- 在这里！
2. **输出**: 解码出的第一个字符是 **'C'**。
3. **更新**: 将工作区间更新为 'C' 的区间 `[0.8, 1.0)`，为解码下一个字符做准备。
#### 步骤 2: 解码第二个字符

现在，我们在 `[0.8, 1.0)` 的“放大镜”下观察。

1. **划分新区间**:
    - `range` = 
    - A的子区间: `[0.8, 0.8 + 0.2*0.5)` = **`[0.8, 0.9)`**
    - B的子区间: `[0.9, 0.9 + 0.2*0.3)` = `[0.9, 0.96)`
    - C的子区间: `[0.96, 1.0)`
2. **定位**: `value` (0.875) 落在哪个新的子区间？
    - 它在 **`[0.8, 0.9)`** 内。
3. **输出**: 解码出的第二个字符是 **'A'**。
4. **更新**: 将工作区间更新为 `[0.8, 0.9)`。

#### 步骤 3: 解码第三个字符

最后一次解码。

1. **划分新区间**:
    - `range` = 
    - A的子区间: `[0.8, 0.8 + 0.1*0.5)` = `[0.8, 0.85)`
    - B的子区间: `[0.85, 0.85 + 0.1*0.3)` = **`[0.85, 0.88)`**
    - C的子区间: `[0.88, 0.9)`
2. **定位**: `value` (0.875) 落在哪个新的子区间？
    - 它在 **`[0.85, 0.88)`** 内。
3. **输出**: 解码出的第三个字符是 **'B'**。

**解码完成。** 我们成功将 `111` 解码回了原始消息 **"CAB"**。

### 率失真函数和量化
消息完全无失真不可实现，连续信源绝对熵无穷大，无失真传输=>信息率R无限大，信道容量C无限大=>物理不可实现
#### 率失真理论
- 有些失真没有必要消除
- 信息率失真理论
- 信息率失真函数：$R(D)$，在允许一定失真度$D$的情况下，信源的输出信息率可以压缩到$R(D)$。
##### 互信息
符号$u$和$v$互相传达的平均信息
平均互信息：
$$I(U;V)=H(V)-H(V|U)=H(U)-H(U|V)=\sum_u\sum_vP(u,v)\log_2\frac{P(u,v)}{P(u)P(v)}$$ 性质：
- 非负性与反身性 $0 \leq I(U;V) = I(V;U)$
- $I(U;V) \leq H(U)$
- $I(V;U) \leq H(V)$
信道编码：信道容量C是发射机和接收机之间互信息的最大值
失真函数：$d(x_i, y_j)=d_{ij}=\alpha \mathbb{1}_{x_i \ne y_j}$
其它表示收发之间误差的失真函数：
- 平方误差函数
- 绝对失真函数
- 相对失真函数：$d(x_i, y_j)=\frac{|y_j-x_i|}{|x_i|}$
设$u$为发送的符号，$v$为接收的符号：
- 平均失真：$D=\mathbb{E}(d(u,v))=\sum_u\sum_v P(u,v)d(u,v)$
- 失真判据：$D \leq D^*$

| 信源             | 平均失真                                                      |
| -------------- | --------------------------------------------------------- |
| 单符号离散无记忆信源压缩传输 | $\bar{D}=\sum_{i=1}^n\sum_{j=1}^mp(x_i)p(y_j\|x_i)d_{ij}$ |
| N次扩展信源（无记忆）    | $\bar{D}(N)=\sum_{k=1}^N \bar{D_K}$                       |
| 连续信源           | $\bar{D}=\iint p(x)p(y\|x)d(x,y)dxdy$                     |
率失真函数 $R(D^*)=\min_{D \leq D^*} \{I(U;V)\}$ 
![[Pasted image 20251127154758.png]]

> [!NOTE]
> Shannon 理论下限：
>$$
>R(D^*)=H(U)-\max_{D \leq D^*} \{H((U-V)|V)\}
>$$
>理想的，源编码器将产生失真U-V，它们与重建信号V在统计上是独立的。
### 无记忆高斯信源的 $R(D^*)$ 函数
无记忆高斯信源是最不利于编码的情况。
> [!NOTE]
> 对于非相关高斯信源，方差为$\sigma^2$，在均方误差$D=\mathbb{E}\{(u-v)^2\}$意义下，其$R(D^*)$为一个斜率为$6dB/Bit$的函数。
> 具有相同方差$\sigma^2$的非高斯信源的$R(D^*)$不高于这条直线。
> $$
> R(D^*)=\max[0, \frac{1}{2}\log_2 \frac{\sigma^2}{D}] 
> $$
> $$
> SNR=10\log_{10} \frac{\sigma^2}{D^*}
> $$
> $$
> SNR\approx6(dB)R
> $$

#### 有记忆高斯信源的 $R(D^*)$ 函数
对于具有功率谱$\varphi_{uu}(\omega)$的联合高斯信源，在均方误差$D=\mathbb{E}\{(u-v)^2\}$意义下，其$R(D^*)$是一个与$\theta$有关的参数方程。
$$
\left\{\begin{align}
D^*=\frac{1}{2\pi}\int_\omega\min(\theta, \Phi_{uu}(\omega)d\omega & \\
R(D^*)=\frac{1}{4\pi}\int_\omega \max(0, \log_2\frac{\Phi_{uu}(\omega)}{\theta}d\omega)
\end{align} \right.
$$
#### 视频信号的率失真函数
高斯pdf信源，其自相关函数按指数递减
$$
R_{uu}(\Delta x, \Delta y) = \exp(-\omega_0 \sqrt{\Delta^2 x + \Delta^2 y})
$$
功率谱密度
$$
\Phi_{uu}(\omega_x,\omega_y)=\frac{2\pi}{\omega_0^2}(1+\frac{\omega_x^2+\omega_y^2}{\omega_0^2})^{(-\frac{3}{2})}
$$
相邻像素间的相关系数：$\omega_0=-\ln (0.93)$
利用谱冗余可以获得的增益：$2.3bit/sample$
### 量化
#### 量化的失真测度
使用MSE衡量失真程度。
$$
D=\sum_{i=1}^M\int_{x_i-1}^{x_i}(x-\hat{x_i})^2f_X(x)dx
$$

#### Lioyd-Max 标量量化器
给定一个固定的量化级数，如何设置每一档的分界线和代表值，才能让最终的总失真最小？
Lioyd-Max 标量量化器是非均匀量化。
##### 条件一：最近邻原则
- 分界线 $b_i$  应该是相邻两个重建值  $y_i$ 和 $y_{i+1}$ 的中点。
##### 条件二：质心原则
- 在某个区间$[b_{i-1}, b_i]$中，选择的量化值$y_i$使得量化精度误差最小，当且仅当$y_i$是$[b_{i-1}, b_i]$的质心。
$$
y_i = \frac{\int_{b_{i-1}}^{b_i} x f_X(x) dx}{\int_{b_{i-1}}^{b_i} f_X(x) dx}

$$

> [!NOTE] 
> Max 量化器迭代设计：
> 1. 计算判决门限：$b_i=\frac{1}{2}(y_i+y_{i+1})$
> 2. 计算新的输出电平：$y_i = \frac{\int_{b_{i-1}}^{b_i} x f_X(x) dx}{\int_{b_{i-1}}^{b_i} f_X(x) dx}$
> 3. 重复1，2，直到失真不能再少


> [!NOTE]
> 对于均匀分布，均匀量化是最佳量化器。

#### 高分辨率量化近似
- 失真率函数：$d(R)=\epsilon^2\sigma_x^22^{-2R}$
- $\epsilon^2\sigma_x^2=\frac{1}{3}[\int_x\sqrt[3]{f_X(x)}dx]^3$


| $\epsilon$ |           |
| ---------- | --------- |
| 1          | 均匀        |
| 4.5        | Laplacian |
| 2.721      | Gaussian  |
#### 熵约束标量量化器
（看到题再补充）
### 矢量量化
格子矢量量化