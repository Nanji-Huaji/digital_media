## 数字化

数字电视广播系统组成：信号源端、压缩编码、系统复用、传输系统
模拟信号数字化：采样、量化、编码
RGB->编码矩阵->采样、量化、编码->$YC_RC_B$
（这里好像不重要）

$$
\begin{align}
Y=0.299R+0.587G+0.114B & \\
C_R=0.713(R-Y)+350 & \\
C_B=0.564(B_Y)+350
\end{align}
$$

350mV 是为了使得色差信号的数值动态范围在 0~700mV

### 取样方式

- 4<=>100% 未抽样
- 每 100%量化为若干 bit
- `J:a:b`是一个标准，用来描述色度相对于亮度的抽样率。**第一个 ‘4’**: 代表**亮度 (Y') 的抽样率**，a 描述第一行的  `J`  个亮度样本中，对应了多少个色度样本（Cb 和 Cr），`b`  描述的是在第二行像素中，相对于第一行，有多少**新**的、**不同**的色度样本。

#### 4:4:4 取样

- 每个分量的每个样本：8（消费，计算机）～ 10（演播室编辑）bit
- 每个像素的样本：24 ～ 30bit
- 四个像素有 4 个 RGB 或 4 个 YCrYb 样本
  ![[Pasted image 20251126211809.png]]

#### 4:2:2 取样

在**水平扫描方向**上，每 2 个 Y 样本有 1 个 Cb 样本和一个 Cr 样本
**4:2:2 保留了全部的垂直色彩信息，但只保留了一半的水平色彩信息。**

- 每 2 个 Y <-> 1 个 Cr，1 个 Cb
- 每个像素：2 个样本
  ![[Pasted image 20251126214605.png]]

#### 4:1:1 取样

![[Pasted image 20251127141912.png]]

#### 4:2:0 MPEG-1 取样

它将颜色信息的垂直和水平分辨率都降低为亮度信息的一半。
MPEG-1 的 4:2:0 抽样规则是“与左上角重合”

```plaintext
   (Cr, Cb,Y) --- (Y)      <-- 色度样本与左上角的亮度样本在同一位置
     |         |
     |         |
    (Y) ----- (Y)

```

#### 4:2:0 MPEG-2 取样

与 MPEG-1 的 4:2:0 相比，MPEG-2 的子采样在水平方向上没有半个象素的偏移。

> 例： 视频某帧的 8×8 块的 Cr 信号值分别如下图 1 所示：:
> (1)画出 Cr 信号经过 4：2：0 MPEG-1 取样后的信号值。
> ![[Pasted image 20251126211614.png]]

解：

$$
Cr_{original} =
\left(
\begin{matrix}
1 & 1 & 0 & 10 & 10 & 1 & 0 & 1 \\
1 & 1 & 0 & 10 & 0 & 0 & 0 & 0 \\
1 & 5 & 0 & 10 & 0 & 0 & 3 & 2 \\
1 & 5 & 0 & 18 & 10 & 1 & 0 & 2 \\
1 & 5 & 0 & 18 & 10 & 1 & 3 & 2 \\
1 & 5 & 0 & 18 & 10 & 1 & 3 & 2 \\
3 & 0 & 0 & 18 & 10 & 1 & 3 & 2 \\
3 & 0 & 0 & 18 & 10 & 1 & 2 & 2 \\
\end{matrix}
\right)
$$

保留 2\*2 方格中左上角的元素，即：

$$
Cr_{original} =
\left(
\begin{matrix}
1 & 0 & 0 & 0 & 10 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
1 & 0 & 0 & 0 & 0 & 0 & 3 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
1 & 0 & 0 & 0 & 10 & 0 & 3 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
3 & 0 & 0 & 0 & 10 & 0 & 3 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
\end{matrix}
\right)
$$

去掉 0，变为

$$

Cr_{sampled} =

\left(

\begin{matrix}

1 & 0 & 10 & 0 \\

1 & 0 & 0 & 3 \\

1 & 0 & 10 & 3 \\

3 & 0 & 10 & 3 \\

\end{matrix}

\right)


$$

### 熵编码

#### 无失真编码

- 游程数据编码
- 变字长编码
  - 哈夫曼编码
  - 算数编码

#### 有失真编码

- 量化
- KLT 编码
- 离散余弦变换
- 小波变换
- DPCM 编码
- 运动估计与补偿

**冗余度：** 定义信息量为$I(x)=-logP(x)$，信息熵是所有可能事件的信息量的平均，即$H(X) = \mathbf{E}\{I(x_j)\} = \sum_{i=1}^n P(x_i)I(x_i) = -\sum_{i=1}^n P(x_i) \log P(x_i)$
当且仅当$X_i$非等概时有冗余。

| 编码     | 冗余                       |
| -------- | -------------------------- |
| 变换编码 | 图像的空间冗余             |
| 预测编码 | 图像或视频的空间或时间冗余 |
| 熵编码   | 信息熵冗余                 |

#### 变字长编码定理

对于一个信息源，我们可以找到一种编码方式，使其平均码长无限接近于该信息源的熵，但不可能小于它。
最佳平均码字长度：$\bar{I_{av}}=\sum_{k=1}^{K-1}I_kP(a_k)$。
且$H(X) < I_{av} < H(X) + 1$。

### Huffman 编码

#### 步骤一：构建霍夫曼树 (The Huffman Tree)

1. **统计频率**：扫描整个数据，统计每个字符（或符号）出现的频率（次数）。
2. **创建节点**：为每个字符创建一个“叶子节点”，每个节点包含字符本身和它的频率。
3. **迭代构建**：
   1. a. 将所有节点放入一个列表或优先队列中，按频率从小到大排序。
   2. b. 从列表中取出**频率最低的两个节点**。
   3. c. 创建一个新的“内部节点”（非叶子节点），其频率是这两个子节点频率之和。
   4. d. 将这两个取出的节点作为新节点的左右子节点。\*\*（哪边是左、哪边是右不影响最终的码长，但会影响具体的编码结果）
   5. e. 将新创建的内部节点放回列表中。
   6. f. **重复步骤 a-e**，直到列表中只剩下一个节点。这个最后的节点就是霍夫 t 曼树的**根节点**。

#### 步骤二：生成编码表 (The Codebook)

1. **分配二进制码**：从根节点开始遍历整个霍夫曼树。
2. 约定一个规则，例如：**向左走记为  `0`，向右走记为  `1`**。
3. 从根节点到每个叶子节点的路径，就构成了该叶子节点对应字符的霍夫曼编码。

#### 算术编码

算术编码将**整个消息**映射到 `[0, 1)` 区间内的一个**小数**。消息越长，这个小数所需的精度就越高。
算术编码**不**需要码表。

#### 1. 初始设置

- **符号和概率**: 首先，需要知道数据源中每个符号的出现概率。
  - A: 0.5 (50%)
  - B: 0.3 (30%)
  - C: 0.2 (20%)
- **初始区间**: 我们从代表所有可能性的区间  `[0.0, 1.0)`  开始。

#### 2. 划分初始区间

根据符号的概率，我们将 `[0, 1)` 区间划分为几个子区间：

- **A**: `[0.0, 0.5)` (占据前 50% 的空间)
- **B**: `[0.5, 0.8)` (占据接下来的 30% 空间, )
- **C**: `[0.8, 1.0)` (占据最后的 20% 空间, )

[0.0] --------- A (50%) --------- [0.5] ---- B (30%) ---- [0.8] -- C (20%) -- [1.0]

#### 3. 编码第一个字符："C"

我们要编码的第一个字符是 'C'。

- 我们选择 'C' 对应的子区间  `[0.8, 1.0)`  作为我们新的“当前区间”。
- 现在，整个消息的编码结果一定是一个以  `0.8...`  开头的小数。

#### 4. 编码第二个字符："A"

接下来编码 'A'。我们**在新的当前区间 `[0.8, 1.0)` 内，再次按照原始概率进行划分**。

- 当前区间的范围长度 (range) 是  。
- 将这个  `0.2`  的范围进行划分：
  - **A's new sub-interval**: `[0.8, 0.8 + 0.2 * 0.5)` = `[0.8, 0.9)`
  - **B's new sub-interval**: `[0.9, 0.9 + 0.2 * 0.3)` = `[0.9, 0.96)`
  - **C's new sub-interval**: `[0.96, 0.96 + 0.2 * 0.2)` = `[0.96, 1.0)`

我们要编码的是 'A'，所以我们选择 'A' 的新子区间 `[0.8, 0.9)` 作为下一个“当前区间”。

#### 5. 编码第三个字符："B"

最后编码 'B'。我们在当前区间 `[0.8, 0.9)` 内重复这个过程。

- 当前区间的范围长度 (range) 是  。
- 将这个  `0.1`  的范围进行划分：
  - **A's final sub-interval**: `[0.8, 0.8 + 0.1 * 0.5)` = `[0.8, 0.85)`
  - **B's final sub-interval**: `[0.85, 0.85 + 0.1 * 0.3)` = `[0.85, 0.88)`
  - **C's final sub-interval**: `[0.88, 0.88 + 0.1 * 0.1)` = `[0.88, 0.9)`

我们要编码的是 'B'，所以最终的区间是 `[0.85, 0.88)`。

对其的编码原则是，**找到一个最短的二进制小数，使其唯一地落在这个区间**。
取最短的`0.111`作为编码结果。

下面演示解码，
解码器接收到二进制码 `111`，并使用完全相同的概率模型来还原消息。
**初始准备:**

1. **二进制码**: `111`
2. **转换为十进制值**: `value` = 0.875
3. **初始区间**: `[0.0, 1.0)`
4. **终止条件**: 假设我们知道消息长度为 3。

#### 步骤 1: 解码第一个字符

1. **定位**: `value` (0.875) 落在初始区间  `[0.0, 1.0)`  的哪个子区间？
   - A: `[0.0, 0.5)`
   - B: `[0.5, 0.8)`
   - **C: `[0.8, 1.0)`** <-- 在这里！
2. **输出**: 解码出的第一个字符是  **'C'**。
3. **更新**: 将工作区间更新为 'C' 的区间  `[0.8, 1.0)`，为解码下一个字符做准备。

#### 步骤 2: 解码第二个字符

现在，我们在 `[0.8, 1.0)` 的“放大镜”下观察。

1. **划分新区间**:
   - `range` =
   - A 的子区间: `[0.8, 0.8 + 0.2*0.5)` = **`[0.8, 0.9)`**
   - B 的子区间: `[0.9, 0.9 + 0.2*0.3)` = `[0.9, 0.96)`
   - C 的子区间: `[0.96, 1.0)`
2. **定位**: `value` (0.875) 落在哪个新的子区间？
   - 它在  **`[0.8, 0.9)`**  内。
3. **输出**: 解码出的第二个字符是  **'A'**。
4. **更新**: 将工作区间更新为  `[0.8, 0.9)`。

#### 步骤 3: 解码第三个字符

最后一次解码。

1. **划分新区间**:
   - `range` =
   - A 的子区间: `[0.8, 0.8 + 0.1*0.5)` = `[0.8, 0.85)`
   - B 的子区间: `[0.85, 0.85 + 0.1*0.3)` = **`[0.85, 0.88)`**
   - C 的子区间: `[0.88, 0.9)`
2. **定位**: `value` (0.875) 落在哪个新的子区间？
   - 它在  **`[0.85, 0.88)`**  内。
3. **输出**: 解码出的第三个字符是  **'B'**。

**解码完成。** 我们成功将 `111` 解码回了原始消息 **"CAB"**。

### 率失真函数和量化

消息完全无失真不可实现，连续信源绝对熵无穷大，无失真传输=>信息率 R 无限大，信道容量 C 无限大=>物理不可实现

#### 率失真理论

- 有些失真没有必要消除
- 信息率失真理论
- 信息率失真函数：$R(D)$，在允许一定失真度$D$的情况下，信源的输出信息率可以压缩到$R(D)$。

##### 互信息

符号$u$和$v$互相传达的平均信息
平均互信息：
$$I(U;V)=H(V)-H(V|U)=H(U)-H(U|V)=\sum_u\sum_vP(u,v)\log_2\frac{P(u,v)}{P(u)P(v)}$$ 性质：

- 非负性与反身性 $0 \leq I(U;V) = I(V;U)$
- $I(U;V) \leq H(U)$
- $I(V;U) \leq H(V)$
  信道编码：信道容量 C 是发射机和接收机之间互信息的最大值
  失真函数：$d(x_i, y_j)=d_{ij}=\alpha \mathbb{1}_{x_i \ne y_j}$
  其它表示收发之间误差的失真函数：
- 平方误差函数
- 绝对失真函数
- 相对失真函数：$d(x_i, y_j)=\frac{|y_j-x_i|}{|x_i|}$
  设$u$为发送的符号，$v$为接收的符号：
- 平均失真：$D=\mathbb{E}(d(u,v))=\sum_u\sum_v P(u,v)d(u,v)$
- 失真判据：$D \leq D^*$

| 信源                         | 平均失真                                                  |
| ---------------------------- | --------------------------------------------------------- |
| 单符号离散无记忆信源压缩传输 | $\bar{D}=\sum_{i=1}^n\sum_{j=1}^mp(x_i)p(y_j\|x_i)d_{ij}$ |
| N 次扩展信源（无记忆）       | $\bar{D}(N)=\sum_{k=1}^N \bar{D_K}$                       |
| 连续信源                     | $\bar{D}=\iint p(x)p(y\|x)d(x,y)dxdy$                     |

率失真函数 $R(D^*)=\min_{D \leq D^*} \{I(U;V)\}$
![[Pasted image 20251127154758.png]]

> [!NOTE]
> Shannon 理论下限：
>
> $$
> R(D^*)=H(U)-\max_{D \leq D^*} \{H((U-V)|V)\}
> $$
>
> 理想的，源编码器将产生失真 U-V，它们与重建信号 V 在统计上是独立的。

### 无记忆高斯信源的 $R(D^*)$ 函数

无记忆高斯信源是最不利于编码的情况。

> [!NOTE]
> 对于非相关高斯信源，方差为$\sigma^2$，在均方误差$D=\mathbb{E}\{(u-v)^2\}$意义下，其$R(D^*)$为一个斜率为$6dB/Bit$的函数。
> 具有相同方差$\sigma^2$的非高斯信源的$R(D^*)$不高于这条直线。
>
> $$
> R(D^*)=\max[0, \frac{1}{2}\log_2 \frac{\sigma^2}{D}]
> $$
>
> $$
> SNR=10\log_{10} \frac{\sigma^2}{D^*}
> $$
>
> $$
> SNR\approx6(dB)R
> $$

#### 有记忆高斯信源的 $R(D^*)$ 函数

对于具有功率谱$\varphi_{uu}(\omega)$的联合高斯信源，在均方误差$D=\mathbb{E}\{(u-v)^2\}$意义下，其$R(D^*)$是一个与$\theta$有关的参数方程。

$$
\left\{\begin{align}
D^*=\frac{1}{2\pi}\int_\omega\min(\theta, \Phi_{uu}(\omega)d\omega & \\
R(D^*)=\frac{1}{4\pi}\int_\omega \max(0, \log_2\frac{\Phi_{uu}(\omega)}{\theta}d\omega)
\end{align} \right.
$$

#### 视频信号的率失真函数

高斯 pdf 信源，其自相关函数按指数递减

$$
R_{uu}(\Delta x, \Delta y) = \exp(-\omega_0 \sqrt{\Delta^2 x + \Delta^2 y})
$$

功率谱密度

$$
\Phi_{uu}(\omega_x,\omega_y)=\frac{2\pi}{\omega_0^2}(1+\frac{\omega_x^2+\omega_y^2}{\omega_0^2})^{(-\frac{3}{2})}
$$

相邻像素间的相关系数：$\omega_0=-\ln (0.93)$
利用谱冗余可以获得的增益：$2.3bit/sample$

### 量化

#### 量化的失真测度

使用 MSE 衡量失真程度。

$$
D=\sum_{i=1}^M\int_{x_i-1}^{x_i}(x-\hat{x_i})^2f_X(x)dx
$$

#### Lioyd-Max 标量量化器

给定一个固定的量化级数，如何设置每一档的分界线和代表值，才能让最终的总失真最小？
Lioyd-Max 标量量化器是非均匀量化。

##### 条件一：最近邻原则

- 分界线 $b_i$   应该是相邻两个重建值   $y_i$  和 $y_{i+1}$ 的中点。

##### 条件二：质心原则

- 在某个区间$[b_{i-1}, b_i]$中，选择的量化值$y_i$使得量化精度误差最小，当且仅当$y_i$是$[b_{i-1}, b_i]$的质心。
  $$
  y_i = \frac{\int_{b_{i-1}}^{b_i} x f_X(x) dx}{\int_{b_{i-1}}^{b_i} f_X(x) dx}
  $$



 > [!NOTE] 
> Max 量化器迭代设计：
> 1. 计算判决门限：$b_i=\frac{1}{2}(y_i+y_{i+1})$
> 2. 计算新的输出电平：$y_i = \frac{\int_{b_{i-1}}^{b_i} x f_X(x) dx}{\int_{b_{i-1}}^{b_i} f_X(x) dx}$
> 3. 重复1，2，直到失真不能再少


> [!NOTE]
> 对于均匀分布，均匀量化是最佳量化器。

#### 高分辨率量化近似
- 失真率函数：$d(R)=\epsilon^2\sigma_x^22^{-2R}$
- $\epsilon^2\sigma_x^2=\frac{1}{3}[\int_x\sqrt[3]{f_X(x)}dx]^3$



| $\epsilon$ |           |
| ---------- | --------- |
| 1          | 均匀        |
| 4.5        | Laplacian |
| 2.721      | Gaussian  |
#### 熵约束标量量化器
（看到题再补充）
### 矢量量化
格子矢量量化

## 变换编码
> [!NOTE]
> 变换编码是进行一种函数变换，从信号域变换到另一个信号域，去除视频信号的空间冗余，能量集中。

### 酉变换

#### 酉矩阵
一个**复数**方阵被称为酉矩阵，如果它的共轭转置等于它的逆。
#### 正交矩阵 (Orthogonal Matrix)
一个**实数**方阵被称为正交矩阵，如果它的转置等于它的逆。

正交矩阵的特点
- 每一行归一
- 两个不同行正交
-  上述两条对于列也成立

### K-L变换
- KLT 去相关，能量集中
#### 协方差矩阵
$R_u = \mathbb{E}((u-m_u)(u-m_u)^T)$
其所有特征向量$\vec{\varphi_i}$（由特征值降序排列）组成矩阵$\phi$，亦即
$$

\phi = [\vec{\varphi_1}, \vec{\varphi_2}, \cdots, \vec{\varphi_{N}}]

$$
定义$\phi^{\dagger}$为变换核，
原来的**列向量** $\vec{\varphi}_i$ 经过共轭转置后，变成了**行向量** $\vec{\varphi}_i^\dagger$。
        $$ A = \begin{pmatrix} \vec{\varphi}_1^\dagger \\ \vec{\varphi}_2^\dagger \\ \vdots \\ \vec{\varphi}_{N}^\dagger \end{pmatrix} $$
通过这种方式，我们将原始数据的能量按照从大到小的顺序，重新分配到了新的坐标轴上。变换后的数据向量 $\vec{v} = (v_1, v_2, \dots, v_{N^2})$ 中，第一个分量 $v_1$ 拥有最大的方差 ($\lambda_1$)，第二个分量 $v_2$ 拥有次大的方差 ($\lambda_2$)，以此类推。


### K-L变换的近似
可以通过删去变换矩阵的最后几行，实现有失真压缩
$$ A’ = \begin{pmatrix} \vec{\varphi}_1^\dagger \\ \vec{\varphi}_2^\dagger \\ \vdots \\ \vec{\varphi}_{N-k}^\dagger \end{pmatrix} $$
这样会使得$v=A'u$变短，删去A的最后几行时，也要对应删去$\phi$的最后几列，从而$u=\phi v$不改变向量维度。

### 离散余弦变换
基函数
$$

    c(k, n) =
    \begin{cases}
    \frac{1}{\sqrt{N}} & k=0, \quad 0 \le n \le N-1 \\
    \sqrt{\frac{2}{N}} \cos\left[\frac{\pi(2n+1)k}{2N}\right] & 1 \le k \le N-1, \quad 0 \le n \le N-1
    \end{cases}
    $$

正变换

$$
    v(k) = \alpha(k) \sum_{n=0}^{N-1} u(n) \cos\left[\frac{\pi(2n+1)k}{2N}\right], \quad 0 \le k \le N-1
$$

其中，归一化系数 $\alpha(k)$ 为:

$$
    \alpha(0) = \sqrt{\frac{1}{N}}, \quad \alpha(k) = \sqrt{\frac{2}{N}} \text{ 对于 } 1 \le k \le N-1
$$

`u(n)`: 你的**输入信号**（比如一行 8 个像素的亮度值）。
`v(k)`: 计算出的**DCT 系数**（比如 8 个频率分量的大小）。`v(0)`是 DC 系数，`v(1)`到`v(7)`是 AC 系数。

二维离散余弦变换：
正变换：$V=CUC^T$
反变换：$U=C^TVC$

$$
C = \sqrt{\frac{2}{N}}
\begin{bmatrix}
\frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}} & \cdots & \frac{1}{\sqrt{2}} \\
\cos\frac{\pi}{2N} & \cos\frac{3\pi}{2N} & \cdots & \cos\frac{(2N-1)\pi}{2N} \\
\vdots & \vdots & \ddots & \vdots \\
\cos\frac{(N-1)\pi}{2N} & \cos\frac{3(N-1)\pi}{2N} & \cdots & \cos\frac{(N-1)(2N-1)\pi}{2N}
\end{bmatrix}_{N \times N}
$$

$$
C_{uv} = \alpha(u) \cos\left[\frac{(2v+1)u\pi}{2N}\right]
$$
### DCT变换系数的比特分配
变换系数的方差是不相等的，因此，每个系数需要不同的量化比特
> [!NOTE]
> 帕累托条件：
> $$\frac{\partial D_i}{\partial R_i} = \frac{\partial D_j}{\partial R_j}$$
> 对于所有$i,j$成立
> 高斯随机向量，在 MSE 失真下对每个变换系数 v 分配的最优码率是
> $$
> R_i = \frac{1}{2} \max((\log_2\frac{\sigma_i^2}{D}), 0) bit
> $$

人眼对信号强度的变化，慢变化部分（低频部分）比细节部分（高频部分）更敏感，亮度比色度更敏感

### 门限编码
丢掉所有低于门限的变换系数
每个变换系数采用具有门限特性的均匀量化器实现，但每个变换系数的量化台阶不同（低频细量化，高频粗量化）
![[Pasted image 20251203143039.png]]
### DCT 变换系数的“之”字形扫描
将一个二维的 8x8 数据块重新排列成一个一维的 64 元素序列。这样做的主要目的是**将大量的“零”聚集在一起**，从而极大地提高后续**游程编码（Run-Length Encoding）的效率
## 预测编码

模型 → 利用以往的样本数据 → 对新样本值进行预测→ 将预测值与实际值相差，进行编码 → 这时差值很小，可以减少编码码位。
![[Pasted image 20251203145910.png]]

DPCM编码器的最终输出频谱  = 理想预测误差的频谱  + 被整形后的量化噪声频谱

#### 噪音整形

$\tilde{E}(\Omega) = (1 - P(\Omega))S(\Omega)$，其中$\tilde{E}(\cdot)$是未经量化的误差的频谱，$P(\cdot)$是线性预测器的频谱，$S(\cdot)$是信号的频谱。

#### 量化误差

$E'(\Omega) = Q(\Omega) + E(\Omega) = Q(\Omega) + (1-P(\Omega))S(\Omega)) - \hat{S}(\Omega) = \tilde{E}(\Omega)+(1-P(\Omega))Q(\Omega)$

#### 量化噪声
- 颗粒噪声
- 边缘忙乱
- 斜度过载

#### 预测编码的收益
- 失真率函数：$d_{DPCM}=\epsilon_e^2\sigma_e^22^{-2R}$
- 预测增益：$G_{DPCM} = \frac{\epsilon_s^2\sigma_s^2}{\epsilon_e^2\sigma_e^2}$
- 对于N维信号，频谱密度$\Phi_{xx}(\Omega)$决定的能达到的预测差值的最小方差：$\sigma_e^2 = \exp\left(\frac{1}{(2\pi)^N} \int_{\Omega} \ln(\Phi_{xx}(\Omega)) d\Omega\right)$

#### Gauss-Markov-1 源的预测编码的增益
- 自相关函数：$E(S_n, S_{n-k}) = \sigma_s^2|\rho|^k$
- 预测增益：
	- $G_{DPCM}=\frac{1}{1-\rho^2}$
	- $SNR=10\log_10\frac{\sigma^2}{D}(dB)$


### 运动估计、补偿
- 运动矢量：编码图象中的当前宏块$M_{PI}$相对于参考图象中的宏块$M{RJ}$所移动的距离和方向
- 宏块$M_{RJ}$是宏块$M_{PI}$的最佳匹配块，所谓最佳匹配是指这两个宏块之s间的差值按某种判决准则最小。

#### 运动矢量搜索
- 块匹配法：以象素块为单位进行运动估计
- 像素递归法：以象素为准进行递归的运动估计

块匹配算法
- 把图象划分为子块
- 每个子块搜索一个运动矢量
- 在一个搜索范围内，搜索最佳的匹配
- 好的搜索算法减少计算量
![[Pasted image 20251205164851.png]]
#### 全搜索
- 逐点搜索，计算代价
- 计算次数：$(M+2d_{max}) \cdot (N+2d_{max})$
#### 二维对数搜索
- 在每一步骤中，在中心及其左右上下 5 个相邻位置上计算判决函数值 MAD。
- 取其中最小的 MAD 值作为下一步计算的中心点
- 如果最小失真在中央或边界，则减少搜索点之间的距离
- 重复上面的步骤，直到找到最佳匹配位置，或中心点到达了搜索区域的边界。
- n 表示在第 n 步上的搜索点，经过 5 步之后，在（i+2,j+6） 点得到位移矢量
![[Pasted image 20251205170504.png]]
#### 三步搜索法
与二维对数法十分相似，不同的是 8 个邻近点进行计算，而且搜索步长随着搜索步骤的增加而减少
#### 分级搜索法

![[Pasted image 20251205175222.png]]
#### 半像素精度
![[Pasted image 20251205180710.png]]
#### 双线性内插
![[Pasted image 20251205180829.png]]
**双线性内插先后在两个方向上各做一次线性内插，来估算一个未知点的像素值。**
![[Pasted image 20251205181057.png]]
### 块方式运动补偿的问题
- 对于低码率，基于块的运动补偿导致明显的块效应。
- 预测差值的 MSE 在块内不是均匀的
#### 重叠块运动补偿
当解码器要生成某个块的预测图像时，它不再是简单地复制粘贴。对于块内的每一个像素，它的预测值是**通过加权平均得到的**。这个平均值综合了以下几个来源的预测：

1. **来自当前块自身运动矢量的预测。**
2. **来自其相邻块（如上方、左方块）运动矢量的预测。**
![[Pasted image 20251205181504.png]]
#### 光流
- 光流是空间运动物体在观察成像平面上的像素运动的瞬时速度。
- 通常将二维图像平面特定坐标点上的灰度瞬时变化率定义为光流矢量。平面上的每一点在时刻t与t+Δt间的位移变化率就是该点的光流矢量，平面上各点的光流矢量组成了该平面的光流场
- 光流法是利用图像序列中像素在时间域上的变化以及相邻帧之间的相关性来找到上一帧跟当前帧之间存在的对应关系，从而计算出相邻帧之间物体的运动信息的一种方法。
> [!NOTE]
> 光流方程：
> $$
 I_xu+I_yv+I_t = 0
 $$
